{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.metrics import roc_curve, roc_auc_score, r2_score, mean_squared_error\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model: Linear Regression, with Feature Engineering\n",
    "For our baseline model, we performed feature engineering to compress time series data into aggregate information (e.g. average acceleration, std of acceleration), in order to transform into tabular data. \n",
    "\n",
    "Some of the assumptions are violated: \n",
    "- data are not iid. Same patients have multiple observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_orig = pd.read_csv(\"processed_data/X_train_original.csv\", index_col=\"Unnamed: 0\")\n",
    "X_test_orig = pd.read_csv(\"processed_data/X_test_original.csv\",  index_col=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"processed_data/X_train_final.csv\", index_col = \"Unnamed: 0\")\n",
    "X_test = pd.read_csv(\"processed_data/X_test_final.csv\", index_col = \"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv(\"processed_data/y_train.csv\",index_col = \"Unnamed: 0\")['on_off']\n",
    "y_test = pd.read_csv(\"processed_data/y_test.csv\",index_col = \"Unnamed: 0\")['on_off']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check correlation matrix of features\n",
    "# help from: https://towardsdatascience.com/better-heatmaps-and-correlation-matrix-plots-in-python-41445d0f2bec\n",
    "\n",
    "corr = X_train_orig.drop(columns=[\"subject_id\",\"measurement_id\"]).corr()\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"correlation matrix heatmap\", fontsize=18)\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap='bwr',\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are highly correlated variables, so regularization is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# drop irrelevant features\n",
    "X_train.drop(columns=[\"subject_id\",\"measurement_id\"],inplace=True)\n",
    "X_test.drop(columns=[\"subject_id\",\"measurement_id\"],inplace=True)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset without patient id information (cluster)\n",
    "X_train_nopatient = X_train.drop(columns=['cluster1','cluster2', 'cluster3'])\n",
    "X_test_nopatient = X_test.drop(columns=['cluster1','cluster2', 'cluster3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.A Generalized Linear Regression (= no patient cluster information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try linear regression, without patient id (cluster) information\n",
    "linreg = LinearRegression().fit(X_train_nopatient, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_scores(model, X_train, y_train, X_test, y_test):\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, model.predict(X_train)))\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, model.predict(X_test)))\n",
    "    rmse_cv = np.sqrt(-np.mean(cross_val_score(model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)))\n",
    "    print(\"Train RMSE:\", rmse_train)\n",
    "    print(\"CV RMSE:\", rmse_cv)\n",
    "    print(\"Test RMSE:\", rmse_test)\n",
    "    return rmse_train, rmse_cv, rmse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Generalized linear regression\")\n",
    "rmse_train_linreg, rmse_cv_linreg, rmse_test_linreg = get_scores(linreg, X_train_nopatient, y_train, X_test_nopatient, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE shares same unit as our ordinal response. This in general means that we are off by 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(linreg.predict(X_test_nopatient))\n",
    "print(y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.B Personalized Linear Regression (= with patient cluster information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try linear regression, without patient id (cluster) information\n",
    "linregper = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Personalized linear regression\")\n",
    "rmse_train_linregper,rmse_cv_linregper, rmse_test_linregper = get_scores(linregper, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.A Generalized Linear Regression with Lasso regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.B Personalized Linear Regression with Lasso regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.A Generalized Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried Random forest regressor, which is a nonlinear model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help from: https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [2,5,10,20,50,100],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [10, 50, 100, 200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a based model\n",
    "rf = RandomForestRegressor(max_features='sqrt')\n",
    "# Instantiate the grid search model\n",
    "generalized_rf = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)\n",
    "generalized_rf.fit(X_train_nopatient, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generalized_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generalized Random Forest Regressor\")\n",
    "rmse_train_rf, rmse_cv_rf, rmse_test_rf = get_scores(generalized_rf, X_train_nopatient, y_train, X_test_nopatient, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.B Personalized Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a based model\n",
    "rf = RandomForestRegressor(max_features='sqrt')\n",
    "# Instantiate the grid search model\n",
    "personalized_rf = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)\n",
    "personalized_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "personalized_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Personalized Random Forest Regressor\")\n",
    "rmse_train_rfper, rmse_cv_rfper, rmse_test_rfper = get_scores(personalized_rf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis: gender stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['on_off'] = y_test\n",
    "data_test_male = X_test.loc[X_test['is_male'] == 1]\n",
    "y_test_male = data_test_male['on_off']\n",
    "X_test_male = data_test_male.drop(columns=['on_off'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Test RMSE for male patients:\")\n",
    "np.sqrt(mean_squared_error(y_test_male, personalized_rf.predict(X_test_male)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['on_off'] = y_test\n",
    "data_test_female = X_test.loc[X_test['is_male'] == 0]\n",
    "y_test_female = data_test_female['on_off']\n",
    "X_test_female = data_test_female.drop(columns=['on_off'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Test RMSE for female patients:\")\n",
    "np.sqrt(mean_squared_error(y_test_female, personalized_rf.predict(X_test_female)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis: label stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['on_off'] = y_test\n",
    "data_test = X_test.loc[X_test['on_off'] == 0]\n",
    "y_test0 = data_test['on_off']\n",
    "X_test0 = data_test.drop(columns=['on_off'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test RMSE for medication status=0:\")\n",
    "np.sqrt(mean_squared_error(y_test0, personalized_rf.predict(X_test0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['on_off'] = y_test\n",
    "data_test = X_test.loc[X_test['on_off'] == 1]\n",
    "y_test1 = data_test['on_off']\n",
    "X_test1 = data_test.drop(columns=['on_off'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test RMSE for medication status=1:\")\n",
    "np.sqrt(mean_squared_error(y_test1, personalized_rf.predict(X_test1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['on_off'] = y_test\n",
    "data_test = X_test.loc[X_test['on_off'] == 2]\n",
    "y_test2 = data_test['on_off']\n",
    "X_test2 = data_test.drop(columns=['on_off'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test RMSE for medication status=2:\")\n",
    "np.sqrt(mean_squared_error(y_test2, personalized_rf.predict(X_test2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['on_off'] = y_test\n",
    "data_test = X_test.loc[X_test['on_off'] == 3]\n",
    "y_test3 = data_test['on_off']\n",
    "X_test3 = data_test.drop(columns=['on_off'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test RMSE for medication status=3:\")\n",
    "np.sqrt(mean_squared_error(y_test3, personalized_rf.predict(X_test3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['on_off'] = y_test\n",
    "data_test = X_test.loc[X_test['on_off'] == 4]\n",
    "y_test4 = data_test['on_off']\n",
    "X_test4 = data_test.drop(columns=['on_off'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Test RMSE for medication status=4:\")\n",
    "np.sqrt(mean_squared_error(y_test4, personalized_rf.predict(X_test4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis: individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try lasso regression, without patient id (cluster) information\n",
    "\n",
    "lasso = LassoCV(cv=5).fit(X_train_nopatient, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(y_train, lasso.predict(X_train_nopatient)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lasso.predict(X_train_nopatient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, lasso.predict(X_test_nopatient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso.predict(X_test_nopatient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try lasso regression, with patient id (cluster) information\n",
    "\n",
    "lasso_per = LassoCV(cv=5).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso_logreg = LogisticRegressionCV(cv=5, multi_class='ovr',penalty='l1',solver='liblinear',max_iter=1000).fit(X_train_nopatient,y_train)\n",
    "lasso_acc = lasso_logreg.score(X_test_nopatient, y_test)\n",
    "print(\"baseline model (lasso) accuracy\")\n",
    "print(f\"train: {lasso_logreg.score(X_train_nopatient, y_train)*100:.2f}%\")\n",
    "print(f\"CV score (k=5): {np.mean(cross_val_score(lasso_logreg, X_train_nopatient, y_train, cv=5))*100:.2f}%\")\n",
    "print(f\"test: {lasso_acc*100:.3f}%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# try without patient id, cluster information\n",
    "logreg = LogisticRegression(multi_class='ovr', penalty='none', solver='lbfgs',max_iter=1000).fit(X_train_nopatient,y_train)\n",
    "baseline_acc = logreg.score(X_test_nopatient, y_test)\n",
    "print(\"baseline model accuracy\")\n",
    "print(f\"train: {logreg.score(X_train_nopatient, y_train)*100:.2f}%\")\n",
    "print(f\"CV score (k=5): {np.mean(cross_val_score(logreg, X_train_nopatient, y_train, cv=5))*100:.2f}%\")\n",
    "print(f\"test: {baseline_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.predict_proba(X_test_nopatient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.predict(X_test_nopatient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train[y_train['on_off'] == 0].shape[0]/y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test[y_test['on_off'] == 0].shape[0]/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline model (without regularization, without patient id information) has very low performance, it's almost similar to random coin toss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso_logreg = LogisticRegressionCV(cv=5,penalty='l1',solver='liblinear',max_iter=1000).fit(X_no_patient,y_train)\n",
    "lasso_acc = lasso_logreg.score(X_no_patient_test, y_test)\n",
    "print(\"baseline model (lasso) accuracy\")\n",
    "print(f\"train: {lasso_logreg.score(X_no_patient, y_train)*100:.2f}%\")\n",
    "print(f\"CV score (k=5): {np.mean(cross_val_score(lasso_logreg, X_no_patient, y_train, cv=5))*100:.2f}%\")\n",
    "print(f\"test: {lasso_acc*100:.3f}%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_logreg.C_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso regularization certainly helps a bit in model performance, by reducing multicollinearity issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wanted to visualize how the data are clustered by reducing the dimensionality of the features through PCA. Specifically, we wanted to see if building a personalized model is a valid approach. Are data grouped by individual patients (even when patient id information is removed)? And how separable are the medication status labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2).fit(X_train_nopatient)\n",
    "print(f\"Total % of variance explained with 2 components: {pca.explained_variance_ratio_.sum()*100:.2f}%\")\n",
    "pca = pca.transform(X_train_nopatient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total % of variance explained is not very high. We need to keep in mind that our 2D plots are not capturing all of the variation in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.scatterplot(pca[:,0], pca[:,1], hue=y_train.values.reshape(y_train.shape[0],), palette=[\"red\",'orange','green','blue','black'], alpha=0.5)\n",
    "plt.title(\"PCA first 2 components (grouped by medication status)\", fontsize=17)\n",
    "plt.xlabel(\"1st principal component\", fontsize=14)\n",
    "plt.ylabel(\"2nd principal component\", fontsize=14)\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this visualization, we can see that the medication labels are not linearly separable. If anything, nonlinear models would work better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_orig = X_train_orig.astype({'subject_id': 'object'})\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.scatterplot(pca[:,0], pca[:,1], hue = X_train_orig.subject_id, \n",
    "                palette=sns.color_palette(\"hls\", 15),\n",
    "                #size=y_train, sizes=(100, 10),\n",
    "                alpha=.8)\n",
    "plt.title(\"PCA first 2 components on CIS-PD patients\", fontsize=17)\n",
    "plt.xlabel(\"1st principal component\", fontsize=14)\n",
    "plt.ylabel(\"2nd principal component\", fontsize=14)\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surely seems like the data are clustered by patients, which suggests that having a personalized model may be more suitable. It is reasonable to assume that individual patients will have differing movement behavior patterns. Since we also won't know the disease progression state of the patient, clustering may help group similar patients together. (Something to keep in mind is that we are not necessarily grouping \"patients\" together, but by similar 20-minute interval blocks together. Each datapoint is not an individual patient, but a patient's unique 20-minute block.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we were to incorporate patient's identity for personalized model, how do we incorporate that information into the model? One-hot encoding won't take into account new patient ids in the future.\n",
    "Some ways: use embedding, or use clustering to find similar patient groups, and input the cluster information instead.\n",
    "(https://datascience.stackexchange.com/questions/37480/how-can-i-do-classification-with-categorical-data-which-is-not-fixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means clustering help from: https://pythonprogramminglanguage.com/kmeans-elbow-method/\n",
    "# BUT Kmeans clustering is not ideal for high dimensional data\n",
    "\n",
    "# k means determine k\n",
    "distortions = []\n",
    "K = range(1,16)\n",
    "for k in K:\n",
    "    kmeans_cluster = KMeans(n_clusters=k).fit(X_no_patient)\n",
    "    distortions.append(sum(np.min(cdist(X_no_patient, kmeans_cluster.cluster_centers_, 'euclidean'), axis=1)) / X_train.shape[0])\n",
    "\n",
    "# Evaluation 1: Elbow method\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k', fontsize=15)\n",
    "plt.ylabel('Distortion',fontsize=15)\n",
    "plt.title('The Elbow Method showing the optimal k', fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like there is an elbow around k=5,6. We can cluster patients by these number of groups, and feed that cluster information for training personalized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation 2: silhouette score\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "scores = [0]\n",
    "for i in range(2,16):\n",
    "    fitx = KMeans(n_clusters=i, init='random', n_init=10, n_jobs=4).fit(X_no_patient)\n",
    "    score = silhouette_score(X_no_patient, fitx.labels_)\n",
    "    scores.append(score)\n",
    "    \n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(range(1,16), np.array(scores), 'bx-')\n",
    "plt.xlabel('$k$', fontsize=15)\n",
    "plt.ylabel('Average Silhouette', fontsize=15)\n",
    "plt.title('The Silhouette Method for $K$-means Clustering', fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Silhouette score reports best k = 2, and k = 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation 3: Gap statistics\n",
    "from gap_statistic import OptimalK\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "gs_obj = OptimalK()\n",
    "\n",
    "_ = gs_obj(X_no_patient, n_refs=400, cluster_array=np.arange(1, 16))\n",
    "\n",
    "def plot_gap(gap_mat):\n",
    "    gaps = gap_mat[\"gap_value\"].values\n",
    "    diffs = gap_mat[\"diff\"]\n",
    "    \n",
    "    err_bars = np.zeros(len(gap_mat))\n",
    "    err_bars[1:] = diffs[:-1] - gaps[:-1] + gaps[1:]\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.scatter(gap_mat[\"n_clusters\"], gap_mat[\"gap_value\"])\n",
    "    plt.errorbar(gap_mat[\"n_clusters\"], gap_mat[\"gap_value\"], yerr=err_bars, capsize=6)\n",
    "    plt.xlabel(\"k\", fontsize=15)\n",
    "    plt.ylabel(\"Gap Statistic\", fontsize=15)\n",
    "    plt.title(\"Gap Statistics method for KMeans clustering\", fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_gap(gs_obj.gap_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gap statistics method reports optimal k=5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize cluster results with PCA\n",
    "best_ks = [2,4,5]\n",
    "for best_k in best_ks:\n",
    "    kmeans_cluster = KMeans(n_clusters=best_k).fit(X_no_patient)\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    sns.scatterplot(pca[:,0], pca[:,1], hue=kmeans_cluster.labels_, \n",
    "                    palette=sns.color_palette(\"hls\", best_k), alpha=0.5, legend=\"full\")\n",
    "    plt.title(f\"KMeans clustering (k={best_k}) results on PCA first 2 components, CIS-PD\", fontsize=15)\n",
    "    plt.xlabel(\"1st principal component\", fontsize=14)\n",
    "    plt.ylabel(\"2nd principal component\", fontsize=14)\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping patients into 2 or 4 clusters seems to be most reasonable, at least based on the limited 2D PCA plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4).fit(X_no_patient)\n",
    "X_train_cluster_label = kmeans.labels_\n",
    "\n",
    "# compare differences of features by groups?\n",
    "X_train_cp = X_train.copy()\n",
    "X_train_cp['cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_cp.groupby('cluster').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train_cp.groupby('cluster').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average variable values are different by different clusters. Looks promising!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model (with patient cluster information)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we tried fitting a model with cluster information of patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cluster_label = kmeans.labels_\n",
    "X_test_cluster_label = kmeans.predict(X_no_patient_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy variables for cluster class \n",
    "onehotencoder = OneHotEncoder(drop='first', categories='auto') \n",
    "\n",
    "# is_1, is_2, is_3\n",
    "X_train_cluster_dummy = onehotencoder.fit_transform(X_train_cluster_label.reshape(-1,1)).toarray() \n",
    "X_test_cluster_dummy = onehotencoder.transform(X_test_cluster_label.reshape(-1,1)).toarray()\n",
    "\n",
    "\n",
    "# append dummy variables of kmeans clustering labels\n",
    "X_train_scaled_cluster = np.hstack((X_no_patient, X_train_cluster_dummy))\n",
    "X_test_scaled_cluster = np.hstack((X_no_patient_test, X_test_cluster_dummy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg2 = LogisticRegression(penalty='none',solver='lbfgs',max_iter=1000).fit(X_train_scaled_cluster,y_train)\n",
    "baseline2_acc = logreg2.score(X_test_scaled_cluster, y_test)\n",
    "print(\"baseline model accuracy (with patient cluster information)\")\n",
    "print(f\"train: {logreg2.score(X_train_scaled_cluster, y_train)*100:.2f}%\")\n",
    "print(f\"CV score (k=5): {np.mean(cross_val_score(logreg2, X_train_scaled_cluster, y_train, cv=5))*100:.2f}%\")\n",
    "print(f\"test: {baseline2_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso2 = LogisticRegressionCV(cv=5,penalty='l1',solver='liblinear',max_iter=1000).fit(X_train_scaled_cluster,y_train)\n",
    "lasso2_acc = lasso2.score(X_test_scaled_cluster, y_test)\n",
    "print(\"baseline model (lasso) accuracy\")\n",
    "print(f\"train: {lasso2.score(X_train_scaled_cluster, y_train)*100:.2f}%\")\n",
    "print(f\"CV score (k=5): {np.mean(cross_val_score(lasso2, X_train_scaled_cluster, y_train, cv=5))*100:.2f}%\")\n",
    "print(f\"test: {lasso2_acc*100:.3f}%\") # very low performance, it's almost similar to random coin toss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso2.C_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There wasn't much improvement even with clustering labels. Perhaps having 15 patients is too small a sample to derive any meaningful information from the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso2.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso2_coef_dict = {}\n",
    "cols = ['age','avg_X', 'std_X', 'min_X', 'max_X', 'range_X',\n",
    "       'avg_Y', 'std_Y', 'min_Y', 'max_Y', 'range_Y', 'avg_Z', 'std_Z',\n",
    "       'min_Z', 'max_Z', 'range_Z', 'is_male', 'cluster1', 'cluster2', 'cluster3']\n",
    "for col, coef in zip(cols, lasso2.coef_[0]):\n",
    "    lasso2_coef_dict[col] = coef\n",
    "\n",
    "print(\"Feature importance, by lasso coefficients:\")\n",
    "{k: v for k, v in sorted(lasso2_coef_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "# keep in mind that lasso regularization arbitrarily chooses some highly correlated variables to drop to zero.\n",
    "# variable interpretation is not too meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help from: https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/\n",
    "# calculate roc curve - generalized baseline model\n",
    "probs = lasso_logreg.predict_proba(X_no_patient_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate roc curve - personalized baseline model\n",
    "probs2 = lasso2.predict_proba(X_test_scaled_cluster)[:,1]\n",
    "fpr2, tpr2, thresholds = roc_curve(y_test, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC plot - personalized model\n",
    "\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "ns_fpr, ns_tpr, thresholds = roc_curve(y_test, ns_probs)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(fpr2, tpr2, c=\"red\", marker='.', label=\"personalized baseline model\")\n",
    "plt.plot(ns_fpr, ns_tpr, c=\"blue\", linestyle='--', label=\"random\")\n",
    "plt.legend(loc=\"best\",fontsize=15)\n",
    "plt.xlabel('False Positive Rate',fontsize=15)\n",
    "plt.ylabel('True Positive Rate',fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy by patients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add diskynesia/tremor symptoms for maybe better clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another method of personalized model: random effects model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_no_patient = pd.DataFrame(data=X_no_patient,\n",
    "             columns=cols)\n",
    "X_no_patient.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statsmodels.api as sm\n",
    "# import statsmodels.formula.api as smf\n",
    "\n",
    "# data_temp = X_no_patient.copy()\n",
    "# data_temp['on_off'] = y_train\n",
    "\n",
    "# md = smf.mixedlm(\"on_off ~ age\", data=data_temp, groups=X_train[\"subject_id\"])\n",
    "# mdf = md.fit()\n",
    "# print(mdf.summary())"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
